# 지수함수(exponential function)
 - 지수함수란 변수가 거듭제곱의 지수에 포함된 함수
 - y＝ax, a가 1이 아닌 양의 상수, x가 모든 실수값일 때의 함수
 - y가 a를 밑으로 하는 지수함수, a의 값에 따라 2가지 경우
 - a > 1일 경우 y = ax는 증가함수, 0 〈 a 〈 1일 경우 감소함수
 - 두 경우 모두 그래프가 y = 0에 가까워지는 점근선 가짐
![](https://i.imgur.com/z5gyjkt.png)

# 로그함수
 - y = logax (a ＞ 0, a ≠ 1)를 a를 밑으로 하는 로그함수
 - 지수함수 y = ax (a ＞ 0, a ≠ 1)의 역함수
 - a의 값에 따라 2가지로 구분되는데, 모두 (1, 0) 점을 통과
 - 두 경우 모두 그래프가 y축에 가까워지는 점근선 가짐
![](https://i.imgur.com/NmbufHg.png)

## 로그함수의 성질
 - 로그함수는 다음과 같은 성질을 가지고 있음
![](https://i.imgur.com/Q3V6YKT.png)
 - 예를 들면 $log_2 16 = 4$
 - 그 이유는 16 = 2 ×2 × 2 × 2 = 24이고 $log_2 2 = 1$이기 때문
 - 또 이와 같은 방법으로 $log_2\frac{1}{2} = −1$이 됨
# 삼각함수(Trigonometric functions)
 - 삼각함수는 각의 크기에 따라 값이 달라지는 함수
 - 대표적인 삼각함수로는 sin(x), cos(x), tan(x) 등
 - 통상 180˚와 같은 각도 표현 대신 π나 π/2와 같은 호도법 사용
![](https://i.imgur.com/tdNKQC1.png)
## 삼각함수 - sin(x)와 cos(x)
 - y = sin(x)와 y = cos(x)의 값은 각각 –1에서 +1 사이의 값을 가짐
 - sin(x)와 cos(x)는 2π를 주기로 같은 모양으로 순환
 - 즉 sin(0) = sin(2π) = 0이고, cos(0) = cos(2π) = 1
 - 또한 sin(π/2) = 1이고 sin(π) = 0, cos(π/2) = 0이고 cos(π) = -1
![](https://i.imgur.com/Pmi4ZuS.png)
## 삼각함수 - tan(x)
 - y = tan(x) 그래프는 π를 주기로 같은 모양으로 순환
 - tan(0) = 0이고 tan(π) = 0
 - tan(π/2)나 tan(-π/2) 등에서는 값이 정의되지 않음
![](https://i.imgur.com/kt1AUUY.png)

# 대표적인 비선형 활성 함수들
 - 신경망에서 뉴런에 해당하는 노드는 비선형적(non-linear)임
 - 특정한 활성 함수(activation function)를 거쳐 출력을 냄
 - 0과 1 사이의 값을 가지는 시그모이드(sigmoid) 함수가 많이 쓰임
 - 시그모이드 함수는 신경망에서 출력을 결정할 때 많이 쓰임

![](https://i.imgur.com/1s1W5Dc.png)

## 비선형 활성 함수들
 - 그 외 활성 함수로는 계단함수, 임계논리 함수 등이 많이 쓰임
 - 계단함수에서는 x축의 값이 음수일 때는 함수의 값이 모두 –1이고, 양수인 경우에는 모두 +1이 됨
 - 임계논리 함수에서는 x축의 값이 음수일 때는 모두 0이고, 0과 1 사이에서는 y = x와 같은 선형의 값을, 그리고 1 이상에서는 모두가 +1임

![](https://i.imgur.com/iKc2zOv.png)

# 손실 함수(loss function)
 -  손실 함수란 예상한 값과 실제값과의 차이를 함수로 정의한 것
 - 신경망에서의 손실 함수는 출력한 값과 실제값과의 오차에 대한 함수
 - 신경망의 학습 과정은 이 오차를 최소로 줄이는 방향으로 진행
 - 대표적인 손실 함수로는 평균제곱오차(MSE : Mean Squared Error)
 - MSE는 예측값과 실제값 사이의 오차의 제곱에 대한 평균값
$$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} \left( \hat{Y}_i - Y_i \right)^2
$$
 - 통상 MSE의 값이 작으면 추정된 값이 정답에 가까운 것이고, MSE의 값이 크면 정답과 멀리 떨어져 있다고 볼 수 있음
 - 그 외의 손실 함수로는 교차 엔트로피 오차(CEE) 등의 방법