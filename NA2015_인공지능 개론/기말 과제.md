# KNN
```python
import pandas as pd  
from sklearn.neighbors import KNeighborsRegressor  
from sklearn.preprocessing import StandardScaler  
from sklearn.model_selection import train_test_split  
  
# 1. 데이터 로드  
df = pd.read_csv('서울시 대기질 자료 제공_2022.csv')  
  
# 2. 데이터 전처리  
# '평균' 데이터 제거  
df = df[df['구분'] != '평균']  
  
# 결측치 제거  
print("결측치 제거 전 데이터 수:", len(df))  
df = df.dropna()  
print("결측치 제거 후 데이터 수:", len(df))  
  
# 일시를 datetime으로 변환  
df['일시'] = pd.to_datetime(df['일시'])  
df['hour'] = df['일시'].dt.hour  
df['month'] = df['일시'].dt.month  
  
# 3. 특성 선택  
X = df[['hour', 'month', '초미세먼지(PM2.5)']]  
y = df['미세먼지(PM10)']  
  
# 4. 데이터 분할  
X_train, X_test, y_train, y_test = train_test_split(  
    X, y, test_size=0.2, random_state=42  
)  
  
# 5. 특성 스케일링  
scaler = StandardScaler()  # 표준화를 해주는 함수 
X_train_scaled = scaler.fit_transform(X_train)  
X_test_scaled = scaler.transform(X_test)  
  
# 6. KNN 모델 학습  
knn = KNeighborsRegressor(n_neighbors=5)  
knn.fit(X_train_scaled, y_train)  
  
# 7. 성능 평가  
score = knn.score(X_test_scaled, y_test)  
print(f"\nR² Score: {score}")  
  
# 8. 예측 예시  
sample = pd.DataFrame({  
    'hour': [12],  
    'month': [12],  
    '초미세먼지(PM2.5)': [40.0]  
})  
sample_scaled = scaler.transform(sample)  
prediction = knn.predict(sample_scaled)  
print(f"\n예측 예시:")  
print(f"시간: 12시, 월: 12월, 초미세먼지: 40.0일 때")  
print(f"예측된 미세먼지 농도: {prediction[0]:.2f}")
```
## 학습 목표 
특정 지역의 미세먼지 농도 예측
## 방법론

## 학습 데이터 

서울시 대기질 자료 제공_2022.csv

## 학습 결과 

## 참고 문헌






# 선형 회귀 
```python
import pandas as pd  
from sklearn.linear_model import LinearRegression  
from sklearn.model_selection import train_test_split  
import numpy as np  
  
# CSV 파일 읽기  
df = pd.read_csv('서울시 대기질 자료 제공_2022.csv')  
  
# 결측치 처리  
print("결측치 처리 전:")  
print(df.isnull().sum())  
df = df.dropna()  
print("\n결측치 처리 후:")  
print(df.isnull().sum())  
  
# 월 데이터 추출  
df['월'] = pd.to_datetime(df['일시']).dt.month  
  
# 지역을 더미 변수로 변환  
df_encoded = pd.get_dummies(df, columns=['구분'])  
  
# 특성과 타겟 분리  
X = df_encoded[[col for col in df_encoded.columns if '구분_' in col] + ['월']]  
y_pm10 = df_encoded['미세먼지(PM10)']  
y_pm25 = df_encoded['초미세먼지(PM2.5)']  
  
# 데이터 분할  
X_train, X_test, y_train_pm10, y_test_pm10 = train_test_split(X, y_pm10, test_size=0.2, random_state=42)  
_, _, y_train_pm25, y_test_pm25 = train_test_split(X, y_pm25, test_size=0.2, random_state=42)  
  
# 모델 학습  
model_pm10 = LinearRegression()  
model_pm25 = LinearRegression()  
  
model_pm10.fit(X_train, y_train_pm10)  
model_pm25.fit(X_train, y_train_pm25)  
  
  
# 사용자 입력 처리 함수  
def get_prediction():  
    unique_regions = df['구분'].unique()  
    print("\n가능한 지역 목록:")  
    for i, region in enumerate(unique_regions):  
        print(f"{i}: {region}")  
  
    month = int(input("\n예측할 월을 입력하세요 (1-12): "))  
    region_idx = int(input("예측할 지역 번호를 입력하세요: "))  
  
    # 입력 데이터 변환  
    test_data = pd.DataFrame(columns=X.columns)  
    test_data.loc[0] = 0  # 모든 컬럼을 0으로 초기화  
    test_data['월'] = month  
    region_col = f'구분_{unique_regions[region_idx]}'  
    test_data[region_col] = 1  
  
    # 예측  
    pm10_pred = model_pm10.predict(test_data)[0]  
    pm25_pred = model_pm25.predict(test_data)[0]  
  
    print(f"\n예측 결과 ({unique_regions[region_idx]}, {month}월)")  
    print(f"미세먼지(PM10) 예측값: {pm10_pred:.1f} ㎍/㎥")  
    print(f"초미세먼지(PM2.5) 예측값: {pm25_pred:.1f} ㎍/㎥")  
  
  
# 모델 평가  
from sklearn.metrics import r2_score, mean_squared_error  
  
print("\n모델 성능 평가:")  
print("PM10:")  
y_pred_pm10 = model_pm10.predict(X_test)  
print(f"R2 score: {r2_score(y_test_pm10, y_pred_pm10):.3f}")  
print(f"RMSE: {np.sqrt(mean_squared_error(y_test_pm10, y_pred_pm10)):.3f}")  
  
print("\nPM2.5:")  
y_pred_pm25 = model_pm25.predict(X_test)  
print(f"R2 score: {r2_score(y_test_pm25, y_pred_pm25):.3f}")  
print(f"RMSE: {np.sqrt(mean_squared_error(y_test_pm25, y_pred_pm25)):.3f}")  
  
# 예측 실행  
while True:  
    try:  
        get_prediction()  
        again = input("\n다른 예측을 하시겠습니까? (y/n): ")  
        if again.lower() != 'y':  
            break  
    except Exception as e:  
        print(f"오류가 발생했습니다: {e}")  
        print("입력 값을 확인해주세요.")
```
## 학습 목표 
특정 지역의 미세먼지 농도 예측
## 방법론
왜 선형 회귀로 선택?
경험상 월에 따라서 미세먼지 수치가 따라가는 선형적인 데이터라고 해석가능하다고 생각함
## 학습 데이터 
미세먼지 및 대기질 데이터
서울시 대기질 자료 제공_2022.csv
## 학습 결과 

## 참고 문헌







# K-mean 
```python
import pandas as pd  
import numpy as np  
from sklearn.preprocessing import StandardScaler  
from sklearn.cluster import KMeans  
from sklearn.metrics import silhouette_score  
import matplotlib.pyplot as plt  
  
# 1. 데이터 읽기  
df = pd.read_csv('LOCAL_PEOPLE_GU_2023.csv')  
  
# 2. 전처리  
meta_columns = ['기준일ID', '시간대구분', '자치구코드', '총생활인구수']  
feature_columns = [col for col in df.columns if col not in meta_columns]  
  
# 3. 데이터 정규화  
scaler = StandardScaler()  
scaled_data = scaler.fit_transform(df[feature_columns])  
scaled_df = pd.DataFrame(scaled_data, columns=feature_columns)  
  
# 4. 최적의 k 찾기  
silhouette_scores = []  
k_range = range(2, 11)  
  
for k in k_range:  
    kmeans = KMeans(n_clusters=k, random_state=42)  
    clusters = kmeans.fit_predict(scaled_df)  
    score = silhouette_score(scaled_df, clusters)  
    silhouette_scores.append(score)  
    print(f'k={k}: silhouette_score={score:.3f}')  
  
# 5. 최적의 k로 클러스터링  
best_k = k_range[np.argmax(silhouette_scores)]  
print(f'\n최적의 k값: {best_k}')  
  
kmeans = KMeans(n_clusters=best_k, random_state=42)  
df['Cluster'] = kmeans.fit_predict(scaled_df)  
  
# 6. 결과 출력  
print('\n각 클러스터의 크기:')  
print(df['Cluster'].value_counts())  
  
# 7. 각 클러스터의 특성 출력  
for cluster in range(best_k):  
    print(f'\n클러스터 {cluster}의 특성:')  
    cluster_data = df[df['Cluster'] == cluster]  
  
    # 평균값 계산  
    mean_values = cluster_data[feature_columns].mean()  
  
    # 상위 3개 특성 출력  
    top_features = mean_values.nlargest(3)  
    print('주요 특성:')  
    for feat, val in top_features.items():  
        print(f'{feat}: {val:.2f}')
```

## 학습 목표 
사고 발생 위치, 사고 유형, 시간대 데이터를 기반으로 **사고 패턴 군집화**
## 방법론

## 학습 데이터 
교통사고 데이터 
## 학습 결과 
k=2: silhouette_score=0.491
k=3: silhouette_score=0.343
k=4: silhouette_score=0.339
k=5: silhouette_score=0.334
k=6: silhouette_score=0.346
k=7: silhouette_score=0.346
k=8: silhouette_score=0.359
k=9: silhouette_score=0.350
k=10: silhouette_score=0.374

k가 높아질수록 점수가 낮아짐
즉 최적의 k는 2

클러스터 1은 77.5%
클러스터 2는 55.5%로 불균형한 분포

클러스터 1은 
- 고령 인구(여성 70세 이상)가 가장 많음
- 중년층(35-49세) 인구가 많음
- 주거 중심 지역의 특성을 보임임
클러스터 2는 
- 고령 인구와 함께 20대 여성 인구가 많음
- 젊은 층과 노년층이 혼재된 특성
- 상업/문화 중심 지역의 특성을 보임
## 참고 문헌
